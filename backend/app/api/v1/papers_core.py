"""
Core Paper Search Endpoints
- Intelligent Hybrid Search
- AI Search Suggestions
- Search Statistics
- Health Checks
"""
import time
import logging
from datetime import datetime
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.orm import Session
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field

from app.core.database import get_db
from app.api.v1.users import get_current_user_id
from app.services.unified_search_service import UnifiedSearchService
from app.services.enhanced_vector_service import EnhancedVectorService
from app.services.ai_query_analyzer import AIQueryAnalyzer
from app.utils.cache import CacheService
from app.core.config import settings

# Configure logging
logger = logging.getLogger(__name__)

router = APIRouter(prefix="/papers", tags=["papers"])

# === Models ===

class PaperResponse(BaseModel):
    id: Optional[int] = None
    title: str
    abstract: Optional[str] = None
    authors: List[str] = []
    publication_date: Optional[str] = None
    pdf_url: Optional[str] = None
    source: str
    arxiv_id: Optional[str] = None
    doi: Optional[str] = None
    semantic_scholar_id: Optional[str] = None
    openalex_id: Optional[str] = None
    citation_count: int = 0
    venue: Optional[str] = None

class SearchResponse(BaseModel):
    papers: List[dict]
    total: int
    query: str
    sources_used: List[str]
    cached: bool

# === Dependencies ===

def get_cache_service():
    return CacheService()

def get_vector_service():
    return EnhancedVectorService()

def get_ai_analyzer():
    return AIQueryAnalyzer()

def get_search_service(
    cache_service: CacheService = Depends(get_cache_service),
    vector_service: EnhancedVectorService = Depends(get_vector_service),
    ai_analyzer: AIQueryAnalyzer = Depends(get_ai_analyzer)
):
    return UnifiedSearchService(cache_service, vector_service, ai_analyzer)

# === Helpers ===

def paper_to_dict(paper) -> dict:
    """Convert Paper model or dict to JSON-serializable dictionary"""
    if isinstance(paper, dict):
        return paper
        
    # Handle SQLAlchemy model
    result = {
        "id": paper.id,
        "title": paper.title,
        "abstract": paper.abstract,
        "authors": paper.authors if paper.authors else [],
        "publication_date": paper.publication_date,
        "pdf_url": paper.pdf_url,
        "source": paper.source,
        "citation_count": paper.citation_count,
        "venue": paper.venue,
        "paper_metadata": paper.paper_metadata if hasattr(paper, 'paper_metadata') else {},
        "is_processed": paper.is_processed if hasattr(paper, 'is_processed') else False,
        "category": paper.category if hasattr(paper, 'category') else "unknown",
        "doi": paper.doi
    }
    
    # Add optional IDs if present
    if hasattr(paper, 'arxiv_id') and paper.arxiv_id:
        result['arxiv_id'] = paper.arxiv_id
    if hasattr(paper, 'semantic_scholar_id') and paper.semantic_scholar_id:
        result['semantic_scholar_id'] = paper.semantic_scholar_id
        
    return result

# === Endpoints ===

@router.get("/unified-search", response_model=SearchResponse)
@router.get("/search", response_model=SearchResponse)
async def unified_search(
    query: str,
    category: str = Query("ai_cs", description="Research category"),
    mode: str = Query("auto", description="Search mode: auto, ai, or normal"),
    limit: int = Query(100, ge=1, le=100, description="Maximum results"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: Session = Depends(get_db),
    search_service: UnifiedSearchService = Depends(get_search_service)
):
    """
    ğŸ” **Intelligent Hybrid Search** - Fast Academic Paper Discovery
    
    **ğŸš€ New Features:**
    - âš¡ **Parallel Search:** Local DB + External APIs simultaneously (3-5s)
    - ğŸ§  **AI Query Analysis:** Auto-detects complex queries vs basic keyword searches
    - ğŸ¯ **Smart Fallback:** If minimal results found, AI retries with improved keywords
    - ğŸ’¾ **Auto-Embedding:** Background task learns from every search result
    - ğŸš€ **Performance:** ~400ms for cached queries, <900ms for text search
    
    **Query Processing:**
    1. **Cache Check:** Instant return if query seen recently
    2. **AI Analysis:** Classifies query (e.g., "transformers for medical imaging")
    3. **Parallel Execution:**
       - **Local Vector Search:** Finds semantically similar papers in DB
       - **External API Fetch:** Arxiv, Semantic Scholar, etc.
    4. **Smart Merge:** Deduplicates and ranks results by relevance + date
    5. **Background Learning:** New papers are auto-embedded for future vector search
    
    **Example:**
    ```
    GET /api/v1/papers/unified-search?query=deep+learning+transformers
    ```
    """
    start_time = time.time()
    
    # 1. Execute Search (Parallel Local + External)
    result = await search_service.search(
        query=query,
        category=category,
        mode=mode, 
        limit=limit,
        db=db
    )
    
    execution_time = time.time() - start_time
    logger.info(f"ğŸš€ Unified Search completed in {execution_time:.2f}s | Found: {result['total']}")
    
    # Map nested metadata to flat response model
    metadata = result.get('metadata', {})
    
    return SearchResponse(
        papers=result['papers'],
        total=result['total'],
        query=metadata.get('query', query),
        # Ensure sources_used is a list (service returns single 'source_used' string)
        sources_used=[metadata.get('source_used', 'unknown')] if isinstance(metadata.get('source_used'), str) else metadata.get('sources_used', []),
        cached=metadata.get('cached', False)
    )

@router.get("/ai-suggestions")
async def get_ai_suggestions(
    query: str,
    goals: Optional[str] = Query(None, max_length=1000, description="Research goals (optional)"),
    category: Optional[str] = Query(None, description="Research category (optional)"),
    ai_analyzer: AIQueryAnalyzer = Depends(get_ai_analyzer)
):
    """
    ğŸ¤– **AI Search Suggestions** - Get Smart Query Recommendations
    """
    try:
        suggestions = await ai_analyzer.generate_suggestions(
            query=query,
            goals=goals,
            category=category
        )
        return suggestions
    except Exception as e:
        logger.error(f"Failed to get AI suggestions: {e}")
        return {
            "original_query": query,
            "suggestions": [],
            "error": str(e)
        }

@router.get("/health")
async def health_check(
    cache_service: CacheService = Depends(get_cache_service)
):
    """Check if search services are operational"""
    # Check cache status
    if hasattr(cache_service, 'use_redis') and not cache_service.use_redis:
        cache_status = "in-memory"
    else:
        try:
            cache_status = "connected" if cache_service.is_connected() else "disconnected"
        except Exception:
            cache_status = "disconnected"

    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "cache": cache_status,
            "search": "operational",
            "database": "connected"
        }
    }

@router.post("/clear-cache")
async def clear_cache():
    """Clear search cache (admin endpoint - add auth later)"""
    cache = CacheService()
    cleared = cache.clear_all()
    return {"status": "success", "cleared_count": cleared}

@router.get("/stats")
async def get_search_stats(db: Session = Depends(get_db)):
    """Get statistics about papers in the database"""
    from sqlalchemy import func
    from app.models.paper import Paper
    
    total_papers = db.query(func.count(Paper.id)).scalar()
    sources = db.query(Paper.source, func.count(Paper.id)).group_by(Paper.source).all()
    
    return {
        "total_papers": total_papers,
        "sources": {s: c for s, c in sources}
    }

@router.get("/categories")
async def get_available_categories():
    """
    Get all available search categories with their configurations
    """
    categories = UnifiedSearchService.get_available_categories()
    
    return {
        "categories": categories,
        "total": len(categories)
    }
