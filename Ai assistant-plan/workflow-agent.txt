# Multi-Agent Workflow Architecture

## ğŸ¯ Core Philosophy

**Conversational AI-First**: Users interact through natural language, not buttons.
**Flexible Delegation**: Agents can call other agents as needed.
**Conflict-Free**: All database operations use proper locking and transactions.
**Production-Ready**: Error handling, monitoring, and scalability built-in.

---

## ğŸ—ï¸ Agent Hierarchy

```
ORCHESTRATOR (Main AI)
â”œâ”€â”€ Understands user intent
â”œâ”€â”€ Creates execution plans
â”œâ”€â”€ Delegates to sub-agents
â””â”€â”€ Synthesizes responses

SUB-AGENTS
â”œâ”€â”€ PAPER AGENT
â”‚   â”œâ”€â”€ PDF processing
â”‚   â”œâ”€â”€ Embedding generation
â”‚   â””â”€â”€ Deduplication
â”‚
â”œâ”€â”€ DATABASE AGENT
â”‚   â”œâ”€â”€ CRUD operations
â”‚   â”œâ”€â”€ Transaction safety
â”‚   â””â”€â”€ Conflict prevention
â”‚
â”œâ”€â”€ ANALYSIS AGENT
â”‚   â”œâ”€â”€ RAG queries
â”‚   â”œâ”€â”€ Paper comparison
â”‚   â””â”€â”€ Gap identification
â”‚
â””â”€â”€ WRITING AGENT
    â”œâ”€â”€ Section generation
    â”œâ”€â”€ Citation formatting
    â””â”€â”€ Document export
```

---

## ğŸ“‹ Example Workflows

### Workflow 1: Upload PDF

```
USER: "I have this transformer paper, can you analyze it?"

ORCHESTRATOR:
  â†“ Classifies intent: upload_paper
  â†“ Creates plan: [check_exists, parse_pdf, embed, store, link]
  
PAPER AGENT (check_exists):
  â†“ Calculate SHA256 hash
  â†“ Query: SELECT * FROM global_papers WHERE file_hash = ?
  â†“ Result: Not found
  
PAPER AGENT (parse_pdf):
  â†“ Use Docling to extract:
    - 8 sections
    - 3 tables
    - 12 equations
    - 5 figures
  
PAPER AGENT (embed):
  â†“ Chunk text (512 tokens, 50 overlap)
  â†“ Generate 156 embeddings (nomic-embed-text-v1.5)
  
DATABASE AGENT (store):
  â†“ BEGIN TRANSACTION
  â†“ INSERT INTO global_papers â†’ paper_id = 42
  â†“ INSERT INTO paper_chunks (156 rows)
  â†“ INSERT INTO paper_assets (tables, equations, figures)
  â†“ COMMIT
  
DATABASE AGENT (link):
  â†“ INSERT INTO user_papers (user_id, global_paper_id)
  
ORCHESTRATOR:
  â†“ Synthesize response:
    "âœ“ Paper processed successfully!
     ğŸ“„ Attention Is All You Need (Vaswani et al., 2017)
     ğŸ“Š Found: 8 sections, 3 tables, 12 equations, 5 figures
     ğŸ§  Generated 156 embeddings
     ğŸ’¾ Stored as Paper #42"
```

### Workflow 2: Generate Methodology Section

```
USER: "Generate the methodology section for my review"

ORCHESTRATOR:
  â†“ Classifies intent: generate_section
  â†“ Creates plan: [get_papers, query_rag, get_schema, generate, save]
  
DATABASE AGENT (get_papers):
  â†“ Query: Get all papers in project_id=5
  â†“ Result: Found 4 papers [#42, #58, #91, #103]
  
ANALYSIS AGENT (query_rag):
  â†“ Generate query embedding
  â†“ pgvector similarity search:
    SELECT pc.text, gp.title, 
           1 - (pc.embedding <=> $query_vec) AS similarity
    FROM paper_chunks pc
    WHERE pc.section_type IN ('methodology', 'experiments')
    ORDER BY similarity DESC
    LIMIT 20
  â†“ Rerank top 8 chunks
  â†“ Compress context (80% reduction)
  
WRITING AGENT (get_schema):
  â†“ Load section template for "methodology"
  â†“ Schema: {title, overview, approaches[], table, synthesis}
  
WRITING AGENT (generate):
  â†“ Call Groq LLM with:
    - Schema structure
    - Retrieved context
    - Instructions: "Academic tone, compare approaches"
  â†“ Result: 800-word section with 12 citations
  
DATABASE AGENT (save):
  â†“ BEGIN TRANSACTION
  â†“ SELECT ... FROM literature_sections FOR UPDATE  -- Lock row
  â†“ UPDATE literature_sections SET content = ...
  â†“ COMMIT
  â†“ Emit WebSocket event: "section_updated"
  
FRONTEND:
  â†“ Receives WebSocket event
  â†“ Refreshes literature review table
  â†“ Shows notification: "Methodology section updated!"
  
ORCHESTRATOR:
  â†“ "âœ“ Methodology section generated!
     ğŸ“ 800 words, 12 citations, 3 tables
     ğŸ“„ Document ready for download"
```

### Workflow 3: Compare Papers

```
USER: "Compare methodologies in my project"

ORCHESTRATOR:
  â†“ Classifies intent: compare_papers
  â†“ Creates plan: [get_papers, query_rag, compare, save]
  
DATABASE AGENT (get_papers):
  â†“ Get papers from project
  
ANALYSIS AGENT (query_rag):
  â†“ Query methodology sections from all papers
  â†“ Retrieve relevant chunks
  
ANALYSIS AGENT (compare):
  â†“ Call LLM with structured prompt:
    "Compare methodologies. Output JSON:
     {comparison_table: [...],
      key_differences: [...],
      similarities: [...]}"
  â†“ Parse structured output
  
DATABASE AGENT (save):
  â†“ BEGIN TRANSACTION
  â†“ UPDATE comparison_configs SET ...
  â†“ INSERT INTO comparison_attributes (multiple rows)
  â†“ COMMIT
  â†“ Emit WebSocket: "comparison_updated"
  
FRONTEND:
  â†“ Comparison tab auto-refreshes
  â†“ Shows populated comparison matrix
  
ORCHESTRATOR:
  â†“ Display rich comparison table
  â†“ Highlight key differences
  â†“ Suggest next actions
```

---

## ğŸ”§ Tool Design Pattern

### Base Tool Class

```python
class BaseTool:
    name: str
    description: str
    parameters: Dict[str, Any]
    
    async def execute(self, **kwargs):
        # 1. Validate parameters
        # 2. Execute logic
        # 3. Log execution
        # 4. Return result
        pass
```

### Example: Update Section Tool

```python
class UpdateSectionTool(BaseTool):
    name = "update_literature_section"
    description = "Update a literature review section with transaction safety"
    parameters = {
        "project_id": "int",
        "section_type": "str",
        "content": "str",
        "metadata": "dict"
    }
    
    async def execute(self, **kwargs):
        # Validate
        self.validate_params(kwargs)
        
        # Execute with transaction
        async with db.begin():
            # Lock row to prevent conflicts
            existing = await db.execute(
                text("""
                    SELECT id FROM literature_sections
                    WHERE project_id = :project_id
                    AND section_type = :section_type
                    FOR UPDATE
                """),
                kwargs
            )
            
            if existing:
                # Update
                await db.execute(
                    text("UPDATE literature_sections SET ..."),
                    kwargs
                )
            else:
                # Insert
                await db.execute(
                    text("INSERT INTO literature_sections ..."),
                    kwargs
                )
            
            await db.commit()
        
        # Log
        self.log_execution(kwargs, result)
        
        # Return
        return {"status": "success", "section_id": ...}
```

---

## ğŸ”„ Inter-Agent Communication

### Agent-to-Agent Delegation

```python
class OrchestratorAgent:
    async def execute(self, task, context):
        # Orchestrator delegates to sub-agent
        result = await self.delegate_to_agent(
            agent_name="database",
            action="update_section",
            context=context
        )
        
        # Use result in next step
        context.metadata.update(result)
        
        # Continue workflow
        ...
```

### Context Passing

```python
class AgentContext:
    user_id: str
    project_id: Optional[int]
    conversation_id: str
    metadata: Dict[str, Any]  # Shared state
    
    # Context flows through entire workflow
    # Each agent can read/write to metadata
```

---

## ğŸ¨ Frontend Integration

### Chat Component

```tsx
function ChatPanel() {
  const [messages, setMessages] = useState([]);
  const [progress, setProgress] = useState(null);
  const ws = useWebSocket(`/api/v1/agent/ws/${conversationId}`);
  
  // Listen for progress events
  useEffect(() => {
    ws.on('agent_progress', (event) => {
      setProgress(event);
    });
    
    ws.on('section_updated', (event) => {
      // Refresh literature review table
      refetchSections();
    });
  }, [ws]);
  
  return (
    <div>
      <MessageList messages={messages} />
      {progress && <ProgressTracker progress={progress} />}
      <ChatInput onSend={sendMessage} />
    </div>
  );
}
```

### Progress Tracker

```tsx
function ProgressTracker({ progress }) {
  return (
    <div className="progress-card">
      <div className="step-indicator">
        {progress.step === 'parsing_pdf' && (
          <>
            <Loader className="animate-spin" />
            <span>Parsing PDF with Docling...</span>
          </>
        )}
        {progress.step === 'generating_embeddings' && (
          <>
            <Brain className="animate-pulse" />
            <span>Generating embeddings ({progress.current}/{progress.total})</span>
          </>
        )}
      </div>
      <ProgressBar value={progress.percentage} />
    </div>
  );
}
```

---

## ğŸ”’ Conflict Prevention

### Database Locking Strategy

```sql
-- WRONG: Race condition possible
UPDATE literature_sections 
SET content = 'new content'
WHERE project_id = 5 AND section_type = 'methodology';

-- RIGHT: Lock row first
BEGIN;
SELECT id FROM literature_sections
WHERE project_id = 5 AND section_type = 'methodology'
FOR UPDATE;  -- Locks the row

UPDATE literature_sections
SET content = 'new content'
WHERE id = <locked_id>;

COMMIT;
```

### Optimistic Locking

```python
# Add version column
class LiteratureSection:
    version: int = 0
    
# Update with version check
UPDATE literature_sections
SET content = :content,
    version = version + 1
WHERE id = :id AND version = :expected_version

# If no rows updated â†’ conflict detected
```

---

## ğŸ“Š Monitoring & Observability

### Structured Logging

```python
logger.info(
    "agent_task_started",
    agent="orchestrator",
    task_id=task_id,
    user_id=user_id,
    intent=intent
)

logger.info(
    "tool_executed",
    tool="update_section",
    duration_ms=duration,
    success=True
)
```

### Metrics

```python
# Track LLM usage
metrics.increment("llm.calls", tags=["model:llama-3.1-70b"])
metrics.histogram("llm.tokens", token_count)
metrics.histogram("llm.cost", cost_usd)

# Track agent performance
metrics.histogram("agent.duration", duration_ms, tags=["agent:orchestrator"])
metrics.increment("agent.errors", tags=["agent:database"])
```

---

## ğŸš€ Deployment Checklist

- [ ] Environment variables configured
- [ ] Database migrations applied
- [ ] pgvector extension installed
- [ ] Redis running (for Celery)
- [ ] Groq API key valid
- [ ] Health checks passing
- [ ] Monitoring enabled
- [ ] Logs aggregated
- [ ] Backups configured
- [ ] Rollback plan ready