# ğŸ”¬ Research Paper Search Platform - Complete Analysis

> **Date**: 2026-01-04 (Updated)  
> **Purpose**: Comprehensive analysis of the entire project architecture for AI Assistant and RAG pipeline.

---

## ğŸ“¦ Project Overview

A full-stack academic research paper search and literature review platform with:
- **Multi-source paper search** (arXiv, Semantic Scholar, OpenAlex, PubMed, Europe PMC, CORE)
- **AI-powered analysis** (embeddings, query analysis, RAG)
- **Literature review workflow** (methodology, findings, comparison, synthesis)
- **AI Assistant** with ReAct agent pattern
- **Automatic PDF processing** for structured content extraction

---

## ğŸ—ï¸ Architecture Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (React + Vite)                 â”‚
â”‚   SearchPage â†’ SearchResults â†’ Workspace â†’ LiteratureReview â”‚
â”‚                           â†“                                 â”‚
â”‚                    AIAssistant (WebSocket)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â†“ HTTP / WebSocket â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (FastAPI)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 16 API Routers:                                         â”‚â”‚
â”‚  â”‚  papers, users, agent, pdf, search-history, folders,    â”‚â”‚
â”‚  â”‚  table-config, methodology, findings, comparison,       â”‚â”‚
â”‚  â”‚  synthesis, analysis, knowledge-base, async-upload,     â”‚â”‚
â”‚  â”‚  health, metrics                                        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                             â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ AgentService â”‚  â”‚ RAGEngine   â”‚  â”‚ UnifiedSearchService â”‚â”‚
â”‚  â”‚  â†“           â”‚  â”‚  â†“          â”‚  â”‚  â†“                   â”‚â”‚
â”‚  â”‚ Orchestrator â”‚  â”‚ LlamaIndex  â”‚  â”‚ Multi-source         â”‚â”‚
â”‚  â”‚  â†“           â”‚  â”‚ Nomic 768d  â”‚  â”‚ (arXiv, S2, OA...)   â”‚â”‚
â”‚  â”‚ FlexibleAgentâ”‚  â”‚ Docling PDF â”‚  â”‚                      â”‚â”‚
â”‚  â”‚  â†“           â”‚  â”‚      â†“      â”‚  â”‚                      â”‚â”‚
â”‚  â”‚ 21 Tools     â”‚  â”‚ PDFExtractorâ”‚  â”‚                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â†“ PostgreSQL + Redis â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DATABASE                               â”‚
â”‚  papers, local_users, user_saved_papers, user_notes,        â”‚
â”‚  user_literature_reviews, comparison_configs, findings,     â”‚
â”‚  synthesis_configs, methodology_data, paper_chunks,         â”‚
â”‚  agent_conversations, agent_messages, llm_usage_logs,       â”‚
â”‚  paper_sections, paper_figures, paper_tables,               â”‚
â”‚  paper_equations, project_summaries                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Complete API Endpoint Map

### Papers & Search
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/papers/search` | GET | Unified multi-source search |
| `/api/v1/papers/ai-suggestions` | GET | AI query recommendations |
| `/api/v1/papers/manual` | POST | Create manual paper |
| `/api/v1/papers/health` | GET | Service health check |
| `/api/v1/papers/stats` | GET | Database statistics |
| `/api/v1/papers/categories` | GET | Available search categories |
| `/api/v1/papers/generate-embeddings` | POST | Generate paper embeddings |

### PDF Processing (NEW)
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/pdf/process` | POST | Process PDF â†’ extract content |
| `/api/v1/pdf/status/{id}` | GET | Get processing status |
| `/api/v1/pdf/batch-process` | POST | Queue multiple PDFs |

### Users & Library
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/users/init` | POST | Initialize user session |
| `/api/v1/users/saved-papers` | GET/POST | Library management |
| `/api/v1/users/saved-papers/{id}` | DELETE | Remove from library |
| `/api/v1/users/notes` | GET/POST | Notes CRUD |
| `/api/v1/users/notes/hierarchy` | GET | Folder structure |
| `/api/v1/users/literature-reviews` | GET/POST/PUT/DELETE | Project CRUD |
| `/api/v1/users/literature-reviews/{id}/seed` | POST | Seed project data |

### Literature Review Workflow
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/projects/{id}/methodology` | GET/PATCH | Methodology data |
| `/api/v1/projects/{id}/findings` | GET | All paper findings |
| `/api/v1/projects/{id}/findings/{paper_id}` | PATCH | Update finding |
| `/api/v1/projects/{id}/findings/gaps` | GET/POST | Research gaps |
| `/api/v1/projects/{id}/comparison/config` | GET/PUT | Comparison settings |
| `/api/v1/projects/{id}/comparison/attributes` | GET/PATCH | Attribute values |
| `/api/v1/projects/{id}/synthesis` | GET | Synthesis table |
| `/api/v1/projects/{id}/synthesis/structure` | PUT | Update structure |
| `/api/v1/projects/{id}/synthesis/cells` | PATCH | Update cell |

### AI Agent
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/v1/agent/chat` | POST | REST chat (collects all) |
| `/api/v1/agent/conversations` | POST | Create conversation |
| `/api/v1/agent/conversations/{id}/history` | GET | Message history |
| `/api/v1/agent/ws/{id}?user_id=X` | WebSocket | Real-time streaming |

---

## ğŸ—„ï¸ Database Schema

> **Database**: PostgreSQL with pgvector  
> **Tables**: 46 total (41 original + 5 new content tables)

### NEW Tables (Paper Content Extraction)
| Table | Purpose |
|-------|---------|
| `paper_sections` | Text sections (abstract, methodology, etc.) + 768-dim embeddings |
| `paper_figures` | Image metadata + captions + file paths |
| `paper_tables` | Table data as markdown/JSON |
| `paper_equations` | LaTeX equations + context |
| `project_summaries` | AI-generated project summaries |

### Core Tables
| Table | Purpose |
|-------|---------|
| `papers` | Global paper repository (386+ rows) |
| `local_users` | User accounts (UUID) |
| `user_saved_papers` | User library with tags/notes |
| `user_notes` | Hierarchical notes with folders |
| `user_literature_reviews` | Projects with status/metadata |

### Literature Review Tables
| Table | Purpose |
|-------|---------|
| `project_papers` | Paper-to-project mapping |
| `methodology_data` | Per-paper methodology analysis |
| `findings` | Key findings + limitations |
| `comparison_configs` | Selected papers + insights |
| `comparison_attributes` | Cell-level attribute data |
| `synthesis_configs` | Table structure (columns/rows) |
| `synthesis_cells` | Cell values |
| `research_gaps` | Identified gaps |

### AI/RAG Tables
| Table | Purpose |
|-------|---------|
| `data_paper_chunks` | RAG chunks with 768-dim embeddings (256 rows) |
| `agent_conversations` | Chat sessions |
| `agent_messages` | User/assistant messages |
| `agent_tool_calls` | Tool execution logs |
| `llm_usage_logs` | Token/cost tracking |

---

## ï¿½ RAG Engine & PDF Parsing Workflow

### RAG Engine Overview (`rag_engine.py`)

The RAG (Retrieval-Augmented Generation) engine uses **LlamaIndex** with **Nomic embeddings** to provide semantic search across paper content.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RAG ENGINE                                     â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ NomicEmbed  â”‚â”€â”€â”€â–¶â”‚ PGVectorStore â”‚â”€â”€â”€â–¶â”‚ VectorStoreIndex         â”‚   â”‚
â”‚  â”‚ 768 dims    â”‚    â”‚ paper_chunks  â”‚    â”‚ + BM25 Hybrid Retrieval  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â–²                                          â”‚                     â”‚
â”‚         â”‚                                          â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Docling PDF  â”‚                         â”‚ Query Engine  â”‚             â”‚
â”‚  â”‚ Parser       â”‚                         â”‚ + Redis Cache â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Configuration
| Component | Setting |
|-----------|---------|
| **Embedding Model** | `nomic-ai/nomic-embed-text-v1.5` |
| **Embedding Dimension** | 768 |
| **Vector Store** | PostgreSQL + pgvector |
| **Chunk Size** | 512 tokens |
| **Chunk Overlap** | 50 tokens |
| **Retrieval** | Hybrid (Vector 70% + BM25 30%) |
| **Cache** | Redis (30 min TTL) |
| **Top-K** | 10 results default |

### RAG Query Workflow

```
User Query: "What methodology did Smith use?"
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. Scope Determination â”‚
        â”‚    - user_id          â”‚
        â”‚    - project_id       â”‚
        â”‚    - paper_ids        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2. Check Redis Cache  â”‚
        â”‚    (30 min TTL)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
           HIT â—„â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–º MISS
            â”‚               â”‚
            â”‚               â–¼
            â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     â”‚ 3. Hybrid Retrieval â”‚
            â”‚     â”‚    Vector + BM25    â”‚
            â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚               â”‚
            â”‚               â–¼
            â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     â”‚ 4. Filter by Scope  â”‚
            â”‚     â”‚    (MetadataFilters)â”‚
            â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚               â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 5. Return Results     â”‚
        â”‚    - text chunks      â”‚
        â”‚    - paper metadata   â”‚
        â”‚    - relevance scores â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“„ PDF Parsing & Content Extraction

### Two-Phase Processing

When a PDF is uploaded/saved, **two parallel processes** run:

```
                    PDF Upload/Save
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: RAG Ingest  â”‚      â”‚ PHASE 2: Content     â”‚
â”‚ (ingest_paper_with_  â”‚      â”‚ Extraction           â”‚
â”‚  docling)            â”‚      â”‚ (process_and_store_  â”‚
â”‚                      â”‚      â”‚  pdf)                â”‚
â”‚ â€¢ Docling parse      â”‚      â”‚                      â”‚
â”‚ â€¢ Export to markdown â”‚      â”‚ â€¢ Extract sections   â”‚
â”‚ â€¢ Chunk (512 tokens) â”‚      â”‚ â€¢ Extract tables     â”‚
â”‚ â€¢ Generate embeddingsâ”‚      â”‚ â€¢ Extract equations  â”‚
â”‚ â€¢ Store in paper_    â”‚      â”‚ â€¢ Store in paper_    â”‚
â”‚   chunks             â”‚      â”‚   sections/tables/   â”‚
â”‚                      â”‚      â”‚   equations          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              Paper is_processed = TRUE
```

### PDF Extractor Functions (`pdf_extractor.py`)

| Function | Purpose |
|----------|---------|
| `extract_sections_from_markdown()` | Parse headings â†’ sections (abstract, methodology, etc.) |
| `extract_tables_from_docling()` | Extract tables from Docling result |
| `extract_equations_from_markdown()` | Extract LaTeX equations ($...$, $$...$$) |
| `process_and_store_pdf()` | Main async function that orchestrates extraction |

### Section Detection Patterns

```python
section_patterns = {
    'abstract': r'(?i)^#+\s*abstract',
    'introduction': r'(?i)^#+\s*introduction',
    'methodology': r'(?i)^#+\s*(methodology|methods|materials\s+and\s+methods)',
    'results': r'(?i)^#+\s*results',
    'discussion': r'(?i)^#+\s*discussion',
    'conclusion': r'(?i)^#+\s*(conclusion|conclusions)',
    'references': r'(?i)^#+\s*references',
    'related_work': r'(?i)^#+\s*(related\s+work|literature\s+review|background)',
}
```

### Content Storage Schema

```sql
-- paper_sections (text content)
paper_id, section_type, section_title, content, word_count, embedding, order_index

-- paper_tables (structured data)
paper_id, table_number, caption, content_markdown, content_json, row_count, column_count

-- paper_equations (math)
paper_id, equation_number, latex, mathml, context, page_number

-- paper_figures (images)
paper_id, figure_number, caption, image_path, image_url, width, height, format
```

---

## ğŸ”„ Complete Data Flow

### End-to-End: Paper to AI Response

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PAPER INGESTION                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   PDF Upload â”€â”€â”€â–¶ Docling Parse â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚        â”‚                              â”‚ Markdown Export â”‚                    â”‚
â”‚        â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚        â–¼                                       â”‚                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚                             â”‚
â”‚   â”‚ papers table    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚   â”‚ (metadata)      â”‚                                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚            â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚            â”‚                    â”‚     PARALLEL PROCESSING      â”‚             â”‚
â”‚            â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚            â–¼                    â–¼              â–¼               â–¼             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ paper_chunksâ”‚      â”‚paper_sectionsâ”‚ â”‚paper_     â”‚ â”‚paper_        â”‚      â”‚
â”‚   â”‚ (embeddings)â”‚      â”‚(text content)â”‚ â”‚tables     â”‚ â”‚equations     â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. USER QUERY                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   User: "Summarize methodology from paper 123"                               â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                          â”‚
â”‚   â”‚ AI Agent     â”‚                                                          â”‚
â”‚   â”‚ (Orchestrator)â—€â”€â”€â”€â”€â”€â”€â”€â”€ Tools Available â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚   â”‚
â”‚          â”‚                                                              â”‚   â”‚
â”‚          â”‚ Thinks: "I need to get the methodology section"              â”‚   â”‚
â”‚          â”‚                                                              â”‚   â”‚
â”‚          â–¼                                                              â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚   â”‚ Tool: get_paper_sections(paper_id=123, section_types=['method']) â”‚ â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚          â”‚                                                              â”‚   â”‚
â”‚          â–¼                                                              â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚   â”‚
â”‚   â”‚ paper_sectionsâ”‚â”€â”€â–¶ "The study used a survey of 500 participants..." â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚   â”‚
â”‚          â”‚                                                              â”‚   â”‚
â”‚          â–¼                                                              â”‚   â”‚
â”‚   AI generates summary based on ACTUAL paper content (no hallucination)     â”‚
â”‚                                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. OPTIONAL: SAVE TO LITERATURE REVIEW                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   AI calls: update_methodology(project_id=1, paper_id=123,                   â”‚
â”‚             methodology_summary="Survey study...", sample_size="500")        â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚   â”‚ methodology_data â”‚                                                      â”‚
â”‚   â”‚ table            â”‚                                                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Files in Workflow

| Step | File | Function |
|------|------|----------|
| PDF Parse | `rag_engine.py` | `ingest_paper_with_docling()` |
| Content Extract | `pdf_extractor.py` | `process_and_store_pdf()` |
| Section Detection | `pdf_extractor.py` | `extract_sections_from_markdown()` |
| RAG Query | `rag_engine.py` | `query()`, `retrieve_only()` |
| Agent Tools | `literature_tools.py` | `get_paper_sections()`, etc. |
| Agent Execute | `orchestrator.py` | `process_message()` |

---

## ï¿½ğŸ¤– AI Assistant Details

### Agent Architecture
```
OrchestratorAgent
    â†“ creates
FlexibleAgent (ReAct pattern)
    â†“ uses
21 Tools:
â”œâ”€â”€ Database: get_project_by_name, get_project_papers, update_comparison, 
â”‚             update_findings, update_methodology, update_synthesis
â”œâ”€â”€ RAG: semantic_search, compare_papers, extract_methodology, get_paper_sections
â”œâ”€â”€ Jobs: parse_pdf, check_job_status
â””â”€â”€ Literature (NEW):
    â”œâ”€â”€ READ: get_paper_sections, get_paper_tables, get_methodology,
    â”‚         get_findings, get_comparison, get_synthesis, get_summary,
    â”‚         list_papers_in_library, list_projects
    â””â”€â”€ WRITE: update_summary
```

### LLM Configuration
| Setting | Value |
|---------|-------|
| Provider | Groq (AsyncGroq) |
| Model | `qwen/qwen3-32b` |
| Max Iterations | 3 |
| Temperature | 0.1 (agent), 0.5 (default) |
| Max Tokens | 1024 |
| Retry | 2 attempts |

### RAG Configuration
| Setting | Value |
|---------|-------|
| Embeddings | nomic-ai/nomic-embed-text-v1.5 (768 dims) |
| Chunk Size | 512 tokens |
| Chunk Overlap | 50 tokens |
| Retrieval | Hybrid (Vector + BM25) |
| PDF Parser | Docling |
| Cache | Redis (30 min TTL) |

---

## ğŸ”„ PDF Processing Pipeline (NEW)

### Auto-Trigger Flow
```
User saves paper to library â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                             â–¼
User uploads PDF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                                          â–¼  â–¼
                                   Check: Already processed?
                                          â”‚
                              YES â—„â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â–º NO
                              (skip)              â”‚
                                                  â–¼
                              Parse PDF with Docling
                                          â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                        â–¼
                        Extract Sections         Extract Tables/Equations
                              â”‚                        â”‚
                              â–¼                        â–¼
                    Store in paper_sections   Store in paper_tables/equations
                              â”‚                        â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â–¼
                              Mark paper.is_processed = TRUE
                                          â”‚
                                          â–¼
                              Ready for ANY user to retrieve!
```

### Trigger Locations
| Trigger | File | When |
|---------|------|------|
| Save to library | `user_service.py` | `save_paper()` â†’ `_trigger_pdf_processing_if_needed()` |
| Upload PDF | `upload_async.py` | After paper created |
| Manual API | `pdf.py` | POST `/api/v1/pdf/process` |

---

## âœ… Bug Fixes Completed

| Issue | Status | Fix Location |
|-------|--------|--------------|
| RAG Engine never initialized | âœ… FIXED | `agent_service.py` - now initializes RAGEngine |
| Async/Sync DB mismatch | âœ… FIXED | `database_tools.py` - all functions now sync |
| Missing tools in orchestrator | âœ… FIXED | `orchestrator.py` - added update_methodology, update_synthesis |
| Frontend selectedPaperIds type | âœ… FIXED | `AIAssistant.tsx` - parseInt() conversion |
| User ID key inconsistency | âœ… FIXED | `AIAssistant.tsx` - both keys checked |
| Too strict loop detection | âœ… FIXED | `base.py` - tracks action+params hash |

---

## ğŸ“Š Project Statistics

| Category | Count |
|----------|-------|
| API Routers | 16 |
| API Endpoints | ~55+ |
| Frontend Components | 87 |
| React Hooks | 9 |
| Database Tables | 46 |
| Agent Tools | 21 |
| Test Files | 35 |

---

## ğŸ—‚ï¸ Key Files Reference

### Backend Core
| File | Purpose |
|------|---------|
| `app/main.py` | FastAPI app + router registration |
| `app/core/rag_engine.py` | LlamaIndex + Docling integration |
| `app/core/pdf_extractor.py` | PDF â†’ sections/tables/equations extraction |
| `app/agents/orchestrator.py` | Agent with 21 tools |
| `app/agents/base.py` | FlexibleAgent ReAct implementation |
| `app/services/agent_service.py` | Conversation management |
| `app/services/user_service.py` | User library + auto PDF trigger |

### Backend Tools
| File | Purpose |
|------|---------|
| `app/tools/database_tools.py` | Project/comparison/findings CRUD |
| `app/tools/literature_tools.py` | Paper sections/summary read/write |
| `app/tools/rag_tools.py` | Semantic search + compare |
| `app/tools/pdf_tools.py` | PDF parsing jobs |

### API Endpoints
| File | Purpose |
|------|---------|
| `app/api/v1/agent.py` | Chat REST + WebSocket |
| `app/api/v1/pdf.py` | PDF processing endpoints |
| `app/api/v1/papers.py` | Paper search + management |
| `app/api/v1/users.py` | User library + notes |
| `app/api/v1/upload_async.py` | PDF upload with processing |

### Frontend Core
| File | Purpose |
|------|---------|
| `src/components/workspace/AIAssistant.tsx` | Chat UI + WebSocket |
| `src/hooks/useUser.ts` | User session management |
| `src/api/client.ts` | Axios with X-User-ID header |
